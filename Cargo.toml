[package]
name = "llama2-rs"
version = "0.1.0"
edition = "2021"
description = "A modern Rust implementation of Llama 2 inference"
authors = ["AI Assistant"]
license = "MIT"

[dependencies]
anyhow = "1.0"
thiserror = "1.0"
clap = { version = "4.0", features = ["derive"] }
memmap2 = "0.9"
rand = "0.8"
rand_pcg = "0.3"
rayon = "1.8"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tokio = { version = "1.0", features = ["full"] }

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"

[profile.dev]
opt-level = 0
debug = true
